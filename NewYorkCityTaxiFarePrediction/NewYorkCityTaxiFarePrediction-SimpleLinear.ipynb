{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First version based on the starter code published at __[kaggle](https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submission.csv', 'train.csv.zip', 'train.csv', 'GCP-Coupons-Instructions.rtf', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # CSV file I/O (e.g. pd.read_csv)\n",
    "import os # reading the input files we have access to\n",
    "\n",
    "print(os.listdir('../datasets/kaggle/new-york-city-taxi-fare-prediction'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "\n",
    "Loading all 55 million rows which does require a lot of RAM, about 18GB for the whole notebook to run. If you have <=16GB, loading a subset should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df =  pd.read_csv('../datasets/kaggle/new-york-city-taxi-fare-prediction/train.csv')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features\n",
    "Add the absolute differences between longitude and latitude values as features. They are a measure of the distance between the start and end of the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                     0\n",
      "fare_amount             0\n",
      "pickup_datetime         0\n",
      "pickup_longitude        0\n",
      "pickup_latitude         0\n",
      "dropoff_longitude     376\n",
      "dropoff_latitude      376\n",
      "passenger_count         0\n",
      "abs_diff_longitude    376\n",
      "abs_diff_latitude     376\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 55423856\n",
      "New size: 55423480\n"
     ]
    }
   ],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune rows that whose longitude and latitude diff values are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 55423480\n",
      "New size: 55308916\n"
     ]
    }
   ],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct training set with the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55308916, 3)\n",
      "(55308916,)\n"
     ]
    }
   ],
   "source": [
    "# Construct and return an Nx3 input matrix for our linear model\n",
    "# using the travel vector, plus a 1.0 for a constant bias term.\n",
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weights using numpy's lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.69009171   9.24874474   6.64366403]\n"
     ]
    }
   ],
   "source": [
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer weights using the Ordinary Least Squares method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.19164103  76.41483685   6.41059403]\n"
     ]
    }
   ],
   "source": [
    "w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_X.T, train_X)), train_X.T), train_y)\n",
    "print(w_OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute RMSE using the weights obtained from both the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse linalg.lstsq = 19.55202121145499\n"
     ]
    }
   ],
   "source": [
    "train_y_w = np.matmul(train_X, w).round(decimals = 2)\n",
    "rmse_w = sqrt(mean_squared_error(train_y, train_y_w))\n",
    "print(\"rmse linalg.lstsq =\", rmse_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse ordinary least squares = 19.47256206805313\n"
     ]
    }
   ],
   "source": [
    "train_y_wOLS = np.matmul(train_X, w_OLS).round(decimals = 2)\n",
    "rmse_wOLS = sqrt(mean_squared_error(train_y, train_y_wOLS))\n",
    "print(\"rmse ordinary least squares =\", rmse_wOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the weights obtained from OLS to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../datasets/kaggle/new-york-city-taxi-fare-prediction/test.csv')\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'NewYorkCityTaxiFarePrediction.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# Reuse the above helper functions to add our features and generate the input matrix.\n",
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)\n",
    "# Predict fare_amount on the test set using our model (w) trained on the training set.\n",
    "test_y_predictions = np.matmul(test_X, w_OLS).round(decimals = 2)\n",
    "\n",
    "# Write the predictions to a CSV file which we can submit to the competition.\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('../datasets/kaggle/new-york-city-taxi-fare-prediction/submission.csv', index = False)\n",
    "\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On submission, a score of 5.74367 was received on the test set which puts it at 532 out of 628 submissions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
